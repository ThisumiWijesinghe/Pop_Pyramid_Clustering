# -*- coding: utf-8 -*-
"""Pop_Pyramid_newipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qVPwk3XMG0zG4PHIyRpp8HRxrmcWfAnS
"""



# Task: Develop a method to cluster countries based on pop pyramids ( Using age_Dataset.csv)


import pandas as pd
import numpy as np
from sklearn.cluster import KMeans,DBSCAN,SpectralClustering
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.sparse.csgraph import laplacian
from sklearn.decomposition import PCA
from sklearn.neighbors import kneighbors_graph

df = pd.read_csv('age_data.csv',low_memory=False)

df = df[['Location','Time', 'AgeGrpStart','PopTotal']].dropna()


#Filter for 2021 year
year_to_use = 2021
df = df[df['Time'] == 2021]

df.dropna(subset=['Location','AgeGrpStart','PopTotal'],inplace=True)

df['AgeGrpStart'] = df['AgeGrpStart'].astype(int)
df['PopTotal'] = df['PopTotal'].astype(float)

recognized_countries = [
    "Afghanistan", "Albania", "Algeria", "Angola", "Argentina",
    "Armenia", "Australia", "Austria", "Azerbaijan", "Bahamas",
    "Belarus", "Belgium", "Belize", "Benin", "Bhutan",
    "Bolivia", "Bosnia and Herzegovina", "Botswana", "Brazil",
    "Bulgaria", "Burkina Faso", "Burundi", "Cambodia", "Cameroon",
    "Canada", "Central African Republic", "Chad", "Chile",
    "China", "Colombia", "Costa Rica", "Croatia", "Cuba",
    "Cyprus", "Czech Republic", "Democratic Republic of the Congo",
    "Denmark", "Djibouti", "Dominican Republic", "Ecuador",
    "Egypt", "El Salvador", "Eritrea", "Estonia", "Eswatini",
    "Ethiopia", "Finland", "France", "Gambia", "Georgia",
    "Germany", "Ghana", "Greece", "Guatemala", "Guinea",
    "Guinea-Bissau", "Guyana", "Haiti", "Honduras", "Hungary",
    "Iceland", "India", "Indonesia", "Iran", "Iraq",
    "Ireland", "Israel", "Italy", "Jamaica", "Japan",
    "Jordan", "Kazakhstan", "Kenya", "Kuwait", "Kyrgyzstan",
    "Laos", "Latvia", "Lebanon", "Lesotho", "Liberia",
    "Libya", "Lithuania", "Madagascar", "Malawi", "Malaysia",
    "Mali", "Malta", "Mauritania", "Mauritius", "Mexico",
    "Moldova", "Mongolia", "Montenegro", "Morocco", "Mozambique",
    "Myanmar", "Namibia", "Nepal", "Netherlands", "New Zealand",
    "Nicaragua", "Niger", "Nigeria", "North Korea", "North Macedonia",
    "Norway", "Oman", "Pakistan", "Panama", "Papua New Guinea",
    "Paraguay", "Peru", "Philippines", "Poland", "Portugal",
    "Qatar", "Romania", "Russia", "Rwanda", "Saint Tome and Principe",
    "Saudi Arabia", "Senegal", "Serbia", "Sierra Leone", "Singapore",
    "Slovakia", "Slovenia", "Somalia", "South Africa", "South Korea",
    "South Sudan", "Spain", "Sri Lanka", "Sudan", "Suriname",
    "Sweden", "Switzerland", "Syria", "Taiwan", "Tajikistan",
    "Tanzania", "Thailand", "Timor-Leste", "Togo", "Trinidad and Tobago",
    "Tunisia", "Turkey", "Turkmenistan", "Tuvalu", "Uganda",
    "Ukraine", "United Arab Emirates", "United Kingdom", "United States",
    "Uruguay", "Uzbekistan", "Vanuatu", "Vatican City", "Venezuela",
    "Vietnam", "Yemen", "Zambia", "Zimbabwe"
]

df = df[df['Location'].isin(valid_countries)]
 print(f"Number of unique countries after filtering:
       {df['Location'].nunique()}")

pivot_df = df.pivot_table(index=['Location'], columns= 'AgeGrpStart', values='PopTotal', fill_value=0)

pivot_df = pivot_df.reindex(columns=sorted(pivot_df.columns),fill_value=0)

pivot_norm = pivot_df.div(pivot_df.sum(axis=1), axis=0)

scaler = StandardScaler()
data_scaled = scaler.fit_transform(pivot_norm)

#PCA
pca = PCA(n_components=2)
data_2d = pca.fit_transform(data_scaled)

#Variance explained Plot
plt.figure(figsize=(6,4))
plt.bar(range(1, len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_*100)
plt.xlabel('Principal Component')
plt.ylabel('Variance Explained(%)')
plt.title('PCA Variance Explained ')
plt.show()


#KMeans Clustering
k = 4
kmeans = KMeans(n_clusters=k, random_state=42)
clusters_kmeans = kmeans.fit_predict(data_scaled)

pivot_norm['Cluster'] = clusters_kmeans

plt.figure(figsize=(8,6))
sns.scatterplot(x=data_2d[:,0],y=data_2d[:,1],hue=clusters_kmeans,palette='tab10')
plt.title('KMeans Clusters (2021)')
plt.xlabel('PCA 1')
plt.ylabel('PCA 2')
plt.legend(title='Cluster')
plt.show()

for cluster_num in range(k):
  cluster_data = pivot_norm[pivot_norm['Cluster'] == cluster_num].drop(columns='Cluster')
  mean_pyramid = cluster_data.mean()

  plt.figure(figsize=(12,6))
  sns.barplot(x=mean_pyramid.index.astype(str), y=mean_pyramid.values)
  plt.title(f'Average Population Pyramid for KMeans cluster {cluster_num}({2021})')
  plt.xlabel('Age Group Start')
  plt.ylabel('Proportion of Population')
  plt.xticks(rotation=45)
  plt.show()

#DBSCAN
dbscan = DBSCAN(eps=0.8, min_samples=7)
dbscan_labels = dbscan.fit_predict(data_scaled)
pivot_norm['DBSCAN_Cluster'] = dbscan_labels

#Analyze DBSCAN clusters
for cluster_num in sorted(set(dbscan_labels)):
  if cluster_num == -1:
    print("Noise points (not assigned to any cluster)")
    continue
  cluster_data = pivot_norm[pivot_norm['DBSCAN_Cluster'] == cluster_num].drop(columns=['Cluster','DBSCAN_Cluster'])
  mean_pyramid = cluster_data.mean()
  plt.figure(figsize=(12,6))
  sns.barplot(x=mean_pyramid.index.astype(str), y=mean_pyramid.values)
  plt.title(f'Average Population Pyramid for DBSCAN cluster {cluster_num} (2021)')
  plt.xlabel('Age Group Start')
  plt.ylabel('Proportion of Population')
  plt.xticks(rotation=45)
  plt.show()

  #Scatter Plot for DBSCAN
plt.figure(figsize=(10, 7))
sns.scatterplot(x=data_2d[:, 0], y=data_2d[:, 1], hue=pivot_norm['DBSCAN_Cluster'], palette='tab10', s=50)
plt.title("DBSCAN Clusters (2021)")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.legend(title='Cluster')
plt.show()

#Spectral Clustering with Eigengap Heuristic

n_neighbors = 10
affinity = kneighbors_graph(data_scaled,n_neighbors=n_neighbors,include_self=True)

laplacian_matrix = laplacian(affinity,normed=True)

eigenvalues,_ = np.linalg.eigh(laplacian_matrix.toarray())

#Plot Eigenvalues for eigengap
plt.figure(figsize=(8,5))
plt.plot(range(1,len(eigenvalues)+1), eigenvalues,marker='o')
plt.xlabel('Index')
plt.ylabel('EigenVlaue')
plt.title('Eigenvalues of graph laplacian for Eigengao Heuristic')
plt.grid(True)
plt.show()

eigengaps = np.diff(eigenvalues)

optimal_clusters = np.argmax(eigengaps)+1
print(f"Optimal no of clusters based on eigengap heuristic:{optimal_clusters}")

spectral = SpectralClustering(n_clusters=optimal_clusters,affinity='nearest_neighbors',n_neighbors=n_neighbors,random_state=42)
spectral_labels = spectral.fit_predict(data_scaled)
pivot_norm['Cluster_Spectral'] = spectral_labels


#Scatter Plot for Spectral Clustering
plt.figure(figsize=(8,6))
sns.scatterplot(x=data_2d[:,0], y=data_2d[:,1],hue = spectral_labels,palette='tab10')
plt.title(f'Spectral Clutering (PCA projection) with {optimal_clusters} clusters')
plt.xlabel('PCA 1')
plt.ylabel('PCA 2')
plt.legend(title='Cluster')
plt.show()

#Plot average pop pyramid per spectral cluster
for cluster_num in range(optimal_clusters):
  cluster_data = pivot_norm[pivot_norm['Cluster_Spectral']== cluster_num].drop(columns=['Cluster','DBSCAN_Cluster','Cluster_Spectral'])
  mean_pyramid = cluster_data.mean()
  plt.figure(figsize=(12,6))
  sns.barplot(x = mean_pyramid.index.astype(str),y = mean_pyramid.values)
  plt.title(f'Average Population Pyramid for Spectral Cluster{cluster_num} (2021)')
  plt.xlabel('Age Group Start')
  plt.ylabel('Proportion of Population')
  plt.xticks(rotation=45)
  plt.show()

  #Function to save countries by cluster
  def list_countries_per_cluster(df, cluster_col, method_name):
    clusters = sorted(df[cluster_col].unique())
    with open(f"{method_name}_cluster_countries.txt", "w") as f:
      for cluster_num in clusters:
        countries = df[df[cluster_col] == cluster_num].index.tolist()
        header = f"Cluster {cluster_num} ({len(countries)}countries):"
        print(header)
        print(countries)
        print("\n")
        f.write(header+ "\n")
        f.write(",".join(countries)+"\n\n")

#Save countries per cluster for all methods
list_countries_per_cluster(pivot_norm, 'Cluster', 'KMeans')
list_countries_per_cluster(pivot_norm,'DBSCAN_Cluster', 'DBSCAN')
list_countries_per_cluster(pivot_norm,'Cluster_Spectral','SpectralClustering')

#Save cluster tasks to csv
pivot_norm.reset_index()[['Location','Cluster', 'DBSCAN_Cluster','Cluster_Spectral']].to_csv('all_clustering_results.csv',index = False)
print("CLuster assignments saved to all_clustering_results.csv")